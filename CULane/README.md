First download and unzip the CULane dataset zip into the root directory of hawp

Rename the folder to temp and run renameAll.py. This is such that when all the images and data are pulled into the same directory, no data is lost.

cd into that directory and run $find . -mindepth 2 -type f -print -exec mv {} . \;

then type mv * ../data/wireframe/images

To load node you need to load the modules
Module load StdEnv/2020
Module load nodejs/12.16.1

run $node create_train_set.js to get train.json. Move this to data/wireframe/
run $node create_val_set.js to get val.json. Move this to data/wireframe/
run $node create_test.js to get test.json. Move this to data/wireframe/

I found that all of the images in the 20 GB zip file were the same size of 1640 x 590 which is why it is hard coded. Initially I had the height and width held by a placeholder of the file's name and fixed the width with cv2 in python which fixed the width and height of all the elements of the json (fixWidth.py)

When training use $sbatch run_train.sh

When checking the training loss or validation loss, rename whichever test set you would like to use as the train test set to be train.json in data/wireframe/ and run $sbatch run_train_test.sh

It will output the loss of each epoch on the specified dataset for a sample of 500 batches or 3000 images (batch size of 6) The results of the script should be in the graham out file generated by the script.

If you want to get the val loss, rename train.json to something else temporarily and rename val.json to train.json

If you want to test the set on the test set run $sbatch run_test.sh and get the results in a json format
Replace their test.py with the test.py in this repo because they test on two datasets while we only need to test on one
(there is a break that I added)

If you want to test it and see the results plotted run $sbatch run_predict.sh
However you must first place the images you want to predict into figures/ and edit run_predict.sh to use the names of the images you chose

Replace their predict.py with the predict.py in this repo because it doesnt display on graham so you need to be able to save it. once it is saved it will be in your root directory under the name of predicted + "number".png

The models that have been trained already can be found here: https://drive.google.com/drive/folders/1C9G5aEmAUSry7DSec90DlJtfPzEIPH8c?usp=sharing